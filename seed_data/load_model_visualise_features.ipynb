{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../fastai/\") # go to parent dir\n",
    "\n",
    "# This file contains all the main external libs we'll use\n",
    "from fastai.imports import *\n",
    "\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "\n",
    "PATH = '/your_path/data/text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sz=224\n",
    "arch=resnext50\n",
    "bs=28\n",
    "\n",
    "tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "data = ImageClassifierData.from_paths(PATH, tfms=tfms, bs=bs)\n",
    "\n",
    "learn = ConvLearner.pretrained(arch, data)\n",
    "\n",
    "learn.load('224_rexnext_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some Helper functions\n",
    "from PIL import Image\n",
    "def image_loader(path, expand_dim=False):\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((sz, sz))\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = np.einsum('ijk->kij', img)\n",
    "    if expand_dim:\n",
    "        img = img[None]\n",
    "    # convert to torch \n",
    "    img = torch.from_numpy(img)\n",
    "    return img \n",
    "\n",
    "def return_sequential(layer_num, model):\n",
    "    return nn.Sequential(\n",
    "            *list(model.children())[:layer_num]\n",
    "        )\n",
    "\n",
    "class get_activation_layer(nn.Module):\n",
    "    def __init__(self, model, total_layers):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.total_layers = total_layers\n",
    "        self.layer_models = []\n",
    "        for i in range(self.total_layers):\n",
    "             self.layer_models.append(return_sequential(i, self.model))\n",
    "    def forward(self, x):\n",
    "        self.outputs = []\n",
    "#         print(x.shape)\n",
    "        for i in range(self.total_layers):\n",
    "            self.outputs.append(self.layer_models[i](x))\n",
    "#             print('shape outputs layer_models[](x) ->',shape(self.outputs[i]))\n",
    "#             print('layer_models[i]', i,'->',self.layer_models[i])\n",
    "        return self.outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_name = 'ittention2.jpg';\n",
    "img_path = f'{PATH}/valid/text/{img_name}'\n",
    "i = image_loader(img_path, expand_dim=True)\n",
    "i = i.cuda()\n",
    "\n",
    "# get actions for the first nr_layers(max:10) layers - the 11th is already FC / flatten\n",
    "nr_layers = 6\n",
    "tmp_model = get_activation_layer(model, nr_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_outputs = tmp_model(Variable(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for index, layer in enumerate(layer_outputs):\n",
    "k = 1 # the number of the layer from 0 to 10\n",
    "j = 1 # the number of the filter between 0 and 2, or between 0 and 63, etc\n",
    "x = layer_outputs[k].data[0][j]\n",
    "# print(shape(x))\n",
    "# print('-', shape(layer_outputs[k].data[0]))\n",
    "# imshow(x)\n",
    "\n",
    "import pathlib\n",
    "\n",
    "pathlib.Path(f'{PATH}/layer_op/{img_name}/').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for k in range(10):\n",
    "    for blocks in layer_outputs[k].data:\n",
    "    #     print(shape(blocks))\n",
    "        for key,block in enumerate(blocks):\n",
    "            plt.figure()\n",
    "            plt.title(key)\n",
    "            plt.imshow(block) \n",
    "#             plt.savefig(f'{PATH}/layer_op/{img_name}/layer_{k}_filter{key}.jpg', dpi=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
